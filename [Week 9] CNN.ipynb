{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Week 9] CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tQpNJJdE8ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWOU5aFP_-l7",
        "colab_type": "text"
      },
      "source": [
        "# CNN(Convolutional Neural Networks)\n",
        "* 고양이 실험에서 시작: 고양이에게 어떤 이미지를 보여줬더니, 그림을 읽어들이는 뉴런들이 특정 그림의 특정 부분에 대해서만 동작하는 것\n",
        "* 즉, 고양이가 이미지를 입력을 나누어서 받아 뉴런에게 나누어진 입력들을 처리하게 된 것\n",
        "\n",
        "<br><br>\n",
        "\n",
        "### 이미지 처리 과정(하나의 convolutioin layer 만들기)\n",
        "1. 먼저 32x32x3 형태의 이미지(또는 벡터)가 존재한다고 하자.  \n",
        "![image](https://user-images.githubusercontent.com/38516906/76270498-d24d3080-62b8-11ea-8f79-40cbf0604ec3.png)\n",
        "  * 이 때 32x32는 크기(width x height) 라고 가정하고, 3(depth)은 이미지 색상의 종류(RGB)라고 생각하자.  \n",
        "  * 그리고 위에서 이야기했던 것과 같이 이미지에 대해 전체적으로 처리하는 것이 아니라, <br> **빨간색 부분과 같이 일부분을 처리**한다고 하자.\n",
        "  * 우리는 이러한 빨간색 부분을 **filter**라고 부르는데, 이 필터의 크기는 우리가 정할 수 있다.<br>이 필터는 전체 이미지의 5x5 영역만 읽어들인다. 그리고 그 영역을 읽어서 하나의 숫자를 뽑아낸다.\n",
        "    * 예외적으로 이미지의 대한 색의 종류, 3은 고정시키고<br>단순히 크기에 대한 형태만 지정할 수 있다.\n",
        "    * 그러니까 7x7x3, 10x10x3같은 것이 가능하다는 말이다.\n",
        "  * 결과물을 하나의 숫자로 표현하기 위해서는 어떻게 해야할까?<br>Wx+b의 형태를 이용해서 뽑아내면 된다.\n",
        "  ![image](https://user-images.githubusercontent.com/38516906/76270702-79ca6300-62b9-11ea-9572-e947d36d3ca4.png)\n",
        "    * 여기서 W는 우리가 어떤 영역에 대해 하나의 숫자를 만들어내는데 사용되는 필터의 값이라고 생각하면 된다.\n",
        " <br>\n",
        "\n",
        "2. 이렇게 결정된 W에 대해 변하지 않도록 고정하고 전체 이미지를 흝도록 한다.<br>즉 아래의 그림과 같이 하나의 필터가 전체의 이미지를 스캔한다.\n",
        "![image](https://user-images.githubusercontent.com/38516906/76270810-dfb6ea80-62b9-11ea-9ff2-e953cdd9c9e4.png)\n",
        "  * 빨간색, 파란색, 초록색 테두리를 가진 것과 같이 하나의 필터를 한 칸 또는 그 이상 씩 이동시키며 전체 이미지를 확인한다.\n",
        "  * 저런 식으로 움직이면, 결과값들은 7x7의 형태를 가지게 될 것이다.\n",
        "  * 이 때 우리가 한칸 씩 필터를 움직였을 때 움직이는 크기를 **stride**라고 한다.<br> 즉, 우리는 strides를 1로 설정한 것이다.\n",
        "    * 그럼 stride를 2로 설정한다면? 아래와 같은 그림이 나올 것이다.\n",
        "    ![image](https://user-images.githubusercontent.com/38516906/76271093-b34f9e00-62ba-11ea-8efc-ca3188252911.png)\n",
        "  * 이 결과물을 바탕으로, 우리는 NxN 형태의 이미지에서 FxF형태의 필터를 이용했을 때 stride를 설정하면 output size를 알아낼 수 있다.  \n",
        "    ![image](https://user-images.githubusercontent.com/38516906/76271170-fc9fed80-62ba-11ea-9527-0078693def46.png)\n",
        "    * 단, 정수로 나눠떨어지지 않을 경우 그 필터의 형태나 stride 사용 불가능\n",
        "<br>\n",
        "\n",
        "3. 그런데, 이렇게 사용하게 되면 기본 이미지보다 output size가 작아지면서 정보 손실의 문제가 발생할 수 있다.\n",
        "* 이를 막기 위한 방법이 바로 **padding**이다.  \n",
        "![image](https://user-images.githubusercontent.com/38516906/76271418-ca42c000-62bb-11ea-8007-86d2d8575062.png)\n",
        "  * 기본 이미지의 모서리에 0이라는 값으로 채워주는 것을 padding이라고 한다.\n",
        "  * padding을 하는 이유는 두 가지가 있는데,\n",
        "    * 이미지의 형태가 급격하게 작아지는 것을 방지\n",
        "    * 이미지의 모서리임을 알려줌\n",
        "  * 위의 사진에서 pad를 1pixel로 설정해서 output size를 확인해보면 7x7이 나오게 된다. 즉 입력 이미지와 출력 이미지의 size가 같게 된다.  \n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "### 여러 convolution layer 만들기\n",
        "* 이러한 방법으로 여러 개의 layer를 만든다. 이 때 새롭게 이용되는 filter는 이전의 filter와 W값이 다를 것이다.\n",
        "![image](https://user-images.githubusercontent.com/38516906/76272370-a0d76380-62be-11ea-89ae-83ee84062272.png)\n",
        "* 이렇게 만들어진 layer들의 형태 (?, ?, ?)에서 마지막 세번째 값을 변경하면서 layer들을 제작한다.\n",
        "![image](https://user-images.githubusercontent.com/38516906/76272494-e72cc280-62be-11ea-8775-a9d932426ee4.png)\n",
        "\n",
        "<br><br>\n",
        "\n",
        "### 기타\n",
        "#### 1) Pooling\n",
        "![image](https://user-images.githubusercontent.com/38516906/76272569-24915000-62bf-11ea-8065-cac75d04033c.png)\n",
        "* CNN의 전체적인 구조를 확인해보면, Convolution과 ReLU가 붙어있으며 중간에 한번 씩 pool을 하게 된다\n",
        "* pool은 간단하게 생각하면, **sampling**이라고 하면 된다.\n",
        "![image](https://user-images.githubusercontent.com/38516906/76272685-69b58200-62bf-11ea-8dc0-e0057ac30ffe.png)\n",
        "  * pooling은 정확하게 말하면, 우리가 입력 이미지에 대해서 convolution layer를 만드는데, 하나의 layer만 뽑아내고 이를 resize하는 과정을 의미한다.\n",
        "  * 말로만 하면 어려우니 예시를 보면서 다시 생각해보록 하자.\n",
        "    * pooling 중에서도 많이 사용되는 max pooling은 아래 사진과 같이 진행된다.\n",
        "  ![image](https://user-images.githubusercontent.com/38516906/76272918-e183ac80-62bf-11ea-8f90-e989b9093ca4.png)\n",
        "    * filter라는 개별을 다시 사용해서, stride는 2로 설정하여 값을 추출한다.<br>max pooling은 그 묶음에서 가장 큰 값을 뽑아낸다.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 2) FC layer (Fully Connected Layer)\n",
        "이전 layer의 모든 node가 다음 layer의 모든 노드에 연결된 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LNOVc1QQqN0",
        "colab_type": "text"
      },
      "source": [
        "### 예제\n",
        "![image](https://user-images.githubusercontent.com/38516906/76273672-c3b74700-62c1-11ea-92fd-38829a17699c.png)\n",
        " * 한 개의 이미지를 3x3으로, 한 가지의 색으로 만들 것이기 때문에 **(1, 3, 3, 1)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yHrWDsmRbwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClxdqRk2Rmm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "8e87105f-9a9c-4dac-d7ac-0d22bb4af96a"
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "image = np.array([[[[1], [2], [3]],\n",
        "                  [[4], [5], [6]],\n",
        "                  [[7], [8], [9]]]], dtype = np.float32)\n",
        "print(image.shape)\n",
        "plt.imshow(image.reshape(3,3), cmap = 'Greys')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8d25f68d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuqgltaeTMoX",
        "colab_type": "text"
      },
      "source": [
        "![image](https://user-images.githubusercontent.com/38516906/76274212-54425700-62c3-11ea-817d-e07a712a448f.png)\n",
        "* filter의 크기는 2x2, 하나의 색상을 가지고, 1개의 필터를 만들 것이기 때문에 **(2,2,1,1)**\n",
        "* 1x2 + 2x1 + 4x1 + 5x1 = 12\n",
        "* padding 관련해서\n",
        "  * same: 결과값이 입력의 shape와 일치하도록 tensorflow에서 자동으로 모서리를 0으로 채움\n",
        "  * valid: 유효 영역만 출력. 결과값이 입력 shape보다 작다(padding 없음)\n",
        "  * 아래 예시를 보면 더욱 빠르게 이해할 수 있을 것 같다.\n",
        "    * Input width = 13\n",
        "    * Filter width = 6\n",
        "    * Stride = 5\n",
        "\n",
        "    ```\n",
        "    # valid: without padding \n",
        "    inputs:     1  2  3  4  5  6  7  8  9  10 11 (12 13)\n",
        "                |________________|                dropped\n",
        "                              |_________________|\n",
        "\n",
        "    # same : with zero padding\n",
        "                pad|                                      |pad\n",
        "    inputs:      0 |1  2  3  4  5  6  7  8  9  10 11 12 13|0  0\n",
        "                |________________|\n",
        "                               |_________________|\n",
        "                                              |________________|\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNIt-vzqR7Bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "f8cf0a68-385b-4612-d9bc-002ac6879dba"
      },
      "source": [
        "print('image.shape', image.shape)\n",
        "weight = tf.constant([[[[1.]], [[1.]]],\n",
        "                      [[[1.]], [[1.]]]])\n",
        "print('weight.shape', weight.shape)\n",
        "\n",
        "\n",
        "\n",
        "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding = 'VALID')\n",
        "conv2d_img = conv2d.eval()\n",
        "print('conv2d_img.shape', conv2d_img.shape)\n",
        "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
        "for i, one_img in enumerate(conv2d_img):\n",
        "  print(one_img.reshape(2,2))\n",
        "  plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image.shape (1, 3, 3, 1)\n",
            "weight.shape (2, 2, 1, 1)\n",
            "conv2d_img.shape (1, 2, 2, 1)\n",
            "[[12. 16.]\n",
            " [24. 28.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAC7CAYAAADGxxq1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-IFU_kipoNI",
        "colab_type": "text"
      },
      "source": [
        "* 그러면 padding을 same으로 둔다면 어떻게 될까?  \n",
        "* 아래 그림처럼 될 것이다.  \n",
        "![image](https://user-images.githubusercontent.com/38516906/76279179-164c2f80-62d1-11ea-8e50-1c7de1155890.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEbV7WMxpn7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "bd31df38-cb65-4055-d885-fef79bf77b20"
      },
      "source": [
        "print('image.shape', image.shape)\n",
        "weight = tf.constant([[[[1.]], [[1.]]],\n",
        "                      [[[1.]], [[1.]]]])\n",
        "print('weight.shape', weight.shape)\n",
        "\n",
        "conv2d = tf.nn.conv2d(image, weight, strides = [1,1,1,1], padding = 'SAME')\n",
        "conv2d_img = conv2d.eval()\n",
        "print('conv2d_img.shape', conv2d_img.shape)\n",
        "for i, one_img in enumerate(conv2d_img):\n",
        "  print(one_img.reshape(3, 3))\n",
        "  plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image.shape (1, 3, 3, 1)\n",
            "weight.shape (2, 2, 1, 1)\n",
            "conv2d_img.shape (1, 3, 3, 1)\n",
            "[[12. 16.  9.]\n",
            " [24. 28. 15.]\n",
            " [15. 17.  9.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAC7CAYAAADVEFpBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCrPEoTBLHAqzxKEwS/4D9lIBLPHdbsAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}